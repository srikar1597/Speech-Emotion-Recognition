# Speech-Emotion-Recognition

Developed and implemented a Speech Emotion Recognition project, utilizing LSTM models and audio features such as MFCC, MEL, chroma, and Tonnetz, achieving 91.5% accuracy in detecting emotions (calm, neutral, surprise, happy, sad, angry, fearful, disgust).
Addressed complex business problems in human-machine interactions by accurately identifying emotional states through speech, leveraging advanced data preprocessing, feature engineering, and model training techniques.
Demonstrated expertise as a machine learning engineer, using various tools and LSTM models to enhance the accuracy and performance of emotion detection, ensuring reliable and consistent results.

